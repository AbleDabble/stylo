## The Plan for the Last 3 Weeks

* Ian - Write functions for the GUI that interface with the backend scraping and twitter scrapers.* 

* William - Build model for authorship authentication and supporting classes and methods


* Sam - Write reddit scraping functions for user profiling


* Andy- Attempted a different method other than streamlistener to ge access to the twitter Public Sample. Ended up not working, next going to try using the streamlistener class to get the correct data.


## What was Done During Last 3 Weeks

* Ian - Wrote basic dummy methods that will be used with the backend python files.

* William - Finished Authorship authentication model, trained all necessary classes and found best class weights i.e. where FAR and FRR intersect.


* Sam - Wrote functions for reddit scraping data collection which appends and formats data correctly to the files in the format needed for the corpus. Ended not needing these bits of code however as a different method was used that did not need a reddit account to function.


* Andy- Trial and error with a different method of pulling Twitter tweets in a mass quantity. Figured out that it won’t work and now going to try the streamlistener class. 

 

## Successes

* Ian - Finished the basic gui mock-up excluding the functionality.


* Andy- No success, just trial and error


* William - Completed authorship authentication model, and the supporting classes for feature extraction, preprocessing and feature selection. Performed testing to find optimal class weight.

* Sam- No successes, but gained a good understanding of reading and writing to files and the scraping workflow.


## Roadblocks Challenges

* Ian- Waiting on team to finish their side so functions can be used as part of the GUI


* Andy - Couldn’t correctly get the public sample from Twitter for the corpus. 


* William - Deep learning framework for authorship profiling and finding suitable hardware for developing the model with a very large dataset. Learning Tensorflow and how neural networks work.


* Sam - Formatting the data to fit the requirements for the copus, parsing string data in python.


## Changes/Deviations from the Plan (if Applicable)

* William - None

* Sam - None

## Description of Goals for Next 3 Weeks

* Ian - Meet with the team and program the GUI to work with the scraping and stylometry python code.


* Andy - Implement the stream listener class. Using this to gain data from the Twitter API public sample, I will then have to format the data storage correctly. 


* Sam - Meet with the team to hook-up the models and other functionality to the GUI.


* William - Complete authorship profiling model


## Confidence on Completion from each Team Member

* Ian - 4

* Andy - 4

* Sam - 4

* William - 4

